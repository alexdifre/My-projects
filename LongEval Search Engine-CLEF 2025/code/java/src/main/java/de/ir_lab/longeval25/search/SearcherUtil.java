package de.ir_lab.longeval25.search;

import java.io.*;
import java.net.HttpURLConnection;
import java.net.URI;
import java.net.URL;
import java.net.URLEncoder;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.SortedMap;
import java.util.TreeMap;

import opennlp.tools.langdetect.Language;
import opennlp.tools.langdetect.LanguageDetectorME;
import opennlp.tools.langdetect.LanguageDetectorModel;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.synonym.SynonymMap;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.benchmark.quality.QualityQuery;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.util.CharsRef;
import org.json.JSONArray;
import org.json.JSONObject;

import com.cohere.api.Cohere;
import com.cohere.api.requests.RerankRequest;
import com.cohere.api.types.RerankRequestDocumentsItem;
import com.cohere.api.types.RerankResponse;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;

import de.ir_lab.longeval25.analyzer.FrenchAnalyzer;
import de.ir_lab.longeval25.parse.ParsedDocument;
import de.ir_lab.longeval25.utility.ConfigManager;

public class SearcherUtil {

    private static final String TABLE_NAME = "mapping";
    private static final ConfigManager config = ConfigManager.getInstance();
    private static final String PUNC = "\\p{Punct}";
    private static final String NEWLINE = System.lineSeparator();

    private SearcherUtil() {
    }

    /**
     * Analyzes a query string using the provided analyzer and returns a list of analyzed tokens.
     *
     * @param analyzer The analyzer to use for tokenization.
     * @param query    The query string to be analyzed.
     * @return A list of tokens generated by analyzing the query string.
     * @throws IOException If an I/O error occurs while analyzing the query.
     */
    public static List<String> queryAnalyzer(Analyzer analyzer, String query) throws IOException {
        List<String> results = new ArrayList<>();

        try (TokenStream stream = analyzer.tokenStream("field", new StringReader(query))) {
            stream.reset();
            final CharTermAttribute tokenTerm = stream.addAttribute(CharTermAttribute.class);

            while (stream.incrementToken())
                results.add(tokenTerm.toString());
            stream.end();
        }
        return results;
    }

    /**
     * Parses the input query string by replacing all punctuation characters with spaces.
     * This method takes a query string as input and replaces all occurrences of punctuation characters with space characters.
     * The method utilizes the {@code PUNC} constant
     *
     * @param query the input query string to be parsed
     * @return the parsed query string with punctuation characters replaced by space characters
     

     /**
     * Pulisce la query rimuovendo la punteggiatura.
     */
    public static String parsQuery(String query) {
        return query.replaceAll(PUNC, " ");
    }

    public static QualityQuery[] readTabDelimitedTopics(BufferedReader reader) throws IOException {
        List<QualityQuery> res = new ArrayList<>();
        String line;

        try {
            while ((line = reader.readLine()) != null) {
                line = line.trim();
                if (line.isEmpty()) {
                    continue;
                }

                // Split migliorato con controllo errori
                String[] parts = line.split("\\t", 2);
                if (parts.length < 2 || parts[1].trim().isEmpty()) {
                    System.err.println("Invalid line skipped: " + line);
                    continue;
                }

                String id = parts[0].trim();
                String queryText = parts[1].trim();

                // Controllo aggiuntivo per query vuote
                if (queryText.isEmpty()) {
                    System.err.println("Empty query for ID: " + id);
                    continue;
                }

                HashMap<String, String> fields = new HashMap<>();
                fields.put("title", queryText);
                res.add(new QualityQuery(id, fields));
            }
        } finally {
            reader.close();
        }

        return res.toArray(new QualityQuery[0]);
    }

    /**
     * Reads topics from a BufferedReader and returns an array of QualityQuery objects.
     *
     * @param reader The BufferedReader from which to read topics.
     * @return An array of QualityQuery objects representing the read topics.
     * @throws IOException if an I/O error occurs while reading topics.
     */
    public static QualityQuery[] readTopics(BufferedReader reader) throws IOException {
        List<QualityQuery> res = new ArrayList<>();
        StringBuilder sb;
        try {
            while (null != read(reader, "<top>", null, false, false)) {
                HashMap<String, String> fields = new HashMap<>();
                // Find id
                sb = read(reader, "<num>", null, true, false);
                String id = sb.substring(sb.indexOf(">") + 1, sb.indexOf("</")).trim();
                // Find title
                sb = read(reader, "<title>", null, true, false);
                String title = sb.substring(sb.indexOf(">") + 1, sb.indexOf("</")).trim();
                // Topic creation
                fields.put("title", title);
                QualityQuery topic = new QualityQuery(id, fields);
                res.add(topic);
            }
        } finally {
            reader.close();
        }
        // Sort result array (by ID)
        QualityQuery[] qq = res.toArray(new QualityQuery[0]);
        return qq;
    }

    private static StringBuilder read(
            BufferedReader reader,
            String prefix,
            StringBuilder sb,
            boolean collectMatchLine,
            boolean collectAll)
            throws IOException {
        sb = (sb == null ? new StringBuilder() : sb);
        String sep = "";
        while (true) {
            String line = reader.readLine();
            if (line == null) {
                return null;
            }
            if (line.startsWith(prefix)) {
                if (collectMatchLine) {
                    sb.append(sep).append(line);
                    sep = NEWLINE;
                }
                break;
            }
            if (collectAll) {
                sb.append(sep).append(line);
                sep = NEWLINE;
            }
        }
        return sb;
    }

    /**
     * Creates a dictionary from a file containing word-to-meaning mappings.
     *
     * @param pathFile The path to the file containing word-to-meaning mappings.
     * @return A list of words extracted from the file.
     * @throws IOException If an I/O error occurs while reading the file.
     */
    public static List<String> createDictionary(String pathFile) throws IOException {
        try (BufferedReader reader = new BufferedReader(new FileReader(pathFile))) {
            String line;
            List<String> dict = new ArrayList<>();
            while ((line = reader.readLine()) != null) {
                String[] word = line.split("=>");
                if (!word[0].trim().isEmpty())
                    dict.add(word[0]);
            }
            return dict;
        }
    }

    /**
     * Converts a map of synonyms to a Lucene SynonymMap.
     *
     * @param synonymMap A map where keys are terms and values are arrays of synonym terms.
     * @return A Lucene SynonymMap built from the provided synonymMap.
     * @throws IOException If an I/O error occurs while building the SynonymMap.
     */
    public static SynonymMap mapToSynonymMap(Map<String, String[]> synonymMap) throws IOException {
        SynonymMap.Builder builder = new SynonymMap.Builder(true);
        for (Map.Entry<String, String[]> entry : synonymMap.entrySet())
            builder.add(new CharsRef(entry.getKey()), new CharsRef(String.join(",", entry.getValue())), false);
        return builder.build();
    }

    /**
     * Reads synonym mappings from a file and returns them as a map.
     *
     * @param synonymMapFile The path to the file containing synonym mappings.
     * @return A map where keys are terms and values are arrays of synonym terms.
     * @throws IOException If an I/O error occurs while reading the file.
     */
    public static Map<String, String[]> readSynonyms(String synonymMapFile) throws IOException {
        try (BufferedReader reader = new BufferedReader(new FileReader(synonymMapFile))) {
            String line;
            Map<String, String[]> m = new HashMap<>();
            while ((line = reader.readLine()) != null) {
                String[] word = line.split("=>");
                if (word.length > 1) {
                    if (!word[1].contains(",")) {
                        String[] synonym = {word[1]};
                        m.put(word[0], synonym);
                    } else
                        m.put(word[0], word[1].split(","));
                }
            }
            return m;
        }
    }

    /**
     * Picks n random elements from the given list of synonyms.
     *
     * @param lst The list of synonyms from which to pick random elements.
     * @param n   The number of random synonyms to pick.
     * @return A list containing n random elements from the input list.
     */
    public static List<String> pickNRandomSynonyms(List<String> lst, int n) {
        List<String> copy = new ArrayList<>(lst);
        Collections.shuffle(copy);
        return n > copy.size() ? copy.subList(0, copy.size()) : copy.subList(0, n);
    }

    // Recupera l'url del documento corrispondente
    public static String getDocUrl(int docId) {
        String url = null;

        try (Connection conn = DriverManager.getConnection(config.getString("dbPath"))) {
            if (conn != null) {
                String query = "SELECT url FROM " + TABLE_NAME + " WHERE id = ?";
                try (PreparedStatement stmt = conn.prepareStatement(query)) {
                    stmt.setInt(1, docId);

                    try (ResultSet rs = stmt.executeQuery()) {
                        url = rs.getString("url");
                    }
                }
            }
        } catch (SQLException e) {
            e.printStackTrace();
        }

        return url;
    }


    /**
     * Sends a POST request to a custom HuggingFace endpoint using the provided prompt,
     * and retrieves related terms generated by a Large Language Model (LLM).
     *
     * <p>This method constructs the request body, sends it to the API, reads the JSON response,
     * extracts the "content" field, cleans and tokenizes it, and returns an array of relevant terms.</p>
     *
     * @param query  the input string representing the prompt to send to the language model
     * @param apiKey the API key used to authorize the HTTP request
     * @return an array of strings containing the related terms generated by the model;
     * returns {@code new String[] {""}} if the HTTP response is not 200 (OK)
     * or if the number of received tokens does not match the expected configuration
     * @throws IOException if an I/O error occurs while sending the request or reading the response
     */
    public static String[] getRelatedTermsFromLLM(String query, String apiKey) throws IOException {
        URL url = URI.create(config.getString("llmServiceUrl")).toURL();
        HttpURLConnection con = (HttpURLConnection) url.openConnection();
        con.setRequestMethod("POST");
        con.setRequestProperty("Authorization", "Bearer ".concat(apiKey));
        con.setRequestProperty("Content-Type", "application/json");
        con.setConnectTimeout(10000);
        con.setReadTimeout(10000);

        String jsonInputString = getBody(query);
        con.setDoOutput(true);
        try (OutputStream os = con.getOutputStream()) {
            byte[] input = jsonInputString.getBytes(StandardCharsets.UTF_8);
            os.write(input, 0, input.length);
        }

        if (con.getResponseCode() != HttpURLConnection.HTTP_OK) {
            System.err.println("Error: " + con.getResponseCode() + " " + con.getResponseMessage());
            return new String[]{""};
        }

        // Read API response
        try (BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream(), StandardCharsets.UTF_8))) {
            StringBuilder responseBuilder = new StringBuilder();
            String line;
            while ((line = br.readLine()) != null)
                responseBuilder.append(line);

            ObjectMapper mapper = new ObjectMapper();
            JsonNode root = mapper.readTree(responseBuilder.toString());

            String content = root.path("choices")
                    .get(0)
                    .path("message")
                    .path("content")
                    .asText();

            String[] newTerms = Arrays.stream(content.split(","))
                    .map(token -> token.replaceAll("[\\n\\t\\r\"']", "").trim())
                    .filter(token -> !token.isEmpty())
                    .toArray(String[]::new);

            if (newTerms.length != config.getInt("numOfTokenFromLLM"))
                System.err.println("The terms returned by the LLM are different from the requested ones");

            return queryAnalyzer(new FrenchAnalyzer(), String.join(" ", newTerms)).toArray(new String[0]);
        }

    }

    private static String getBody(String query) {
        if (config.getString("llmServiceUrl").contains("api.openai.com"))
            return """
                    {
                      "model": "gpt-3.5-turbo",
                      "messages": [
                        {
                          "role": "user",
                          "content": "Écris UNIQUEMENT %d mots relatifs à ce sujet : %s, séparés par une virgule. Pas de phrases ni ponctuation."
                        }
                      ],
                      "max_tokens": 50,
                      "temperature": 0.5,
                      "top_p": 0.9
                    }
                    """.formatted(config.getInt("numOfTokenFromLLM"), query);
        else
            return """
                    {
                        "messages": [
                            {
                                "role": "user",
                                "content": "Écris UNIQUEMENT %d mots relatifs à ce sujet : %s, séparés par une virgule."
                            }
                        ],
                        "model": "deepseek/deepseek-v3-0324",
                        "max_tokens": 20,
                        "temperature": 0.5,
                        "top_p": 0.9
                    }
                    """.formatted(config.getInt("numOfTokenFromLLM"), query);


    }

    public static String[] getRelatedTermsWord2Vec(List<String> query) throws IOException {
        List<String> allRelatedTerms = new ArrayList<>();
        ObjectMapper mapper = new ObjectMapper();

        for (String token : query) {
            URL url = URI.create("http://localhost:8081/similar?word=" + URLEncoder.encode(token, StandardCharsets.UTF_8)).toURL();
            HttpURLConnection con = (HttpURLConnection) url.openConnection();
            con.setRequestMethod("GET");
            con.setRequestProperty("Accept", "application/json");
            con.setConnectTimeout(10000);
            con.setReadTimeout(10000);

            if (con.getResponseCode() == 200) {
                try (BufferedReader br = new BufferedReader(new InputStreamReader(con.getInputStream()))) {
                    String[] relatedTerms = mapper.readValue(br, String[].class);
                    allRelatedTerms.addAll(Arrays.asList(relatedTerms));
                } finally {
                    con.disconnect();
                }
            } else
                return new String[]{""};
        }
        return queryAnalyzer(new FrenchAnalyzer(), String.join(" ", allRelatedTerms)).toArray(new String[0]);
    }

    public static String[] getRelatedTermsFromPrf(ScoreDoc[] scoreDocs, IndexReader reader) throws IOException {
        Analyzer analyzer = new FrenchAnalyzer();
        Map<String, Integer> termFreq = new HashMap<>();

        // Iterate over top-ranked documents
        for (ScoreDoc doc : scoreDocs) {
            // Extract the "body" field from each document
            String body = reader.storedFields().document(doc.doc).get(ParsedDocument.FIELDS.BODY);

            // Tokenize the body content using the analyzer
            List<String> tokens = queryAnalyzer(analyzer, body);

            // Count the frequency of each token (ignoring very short ones)
            for (String token : tokens) {
                if (token.length() > 2) {
                    termFreq.put(token, termFreq.getOrDefault(token, 0) + 1);
                }
            }
        }

        // Sort tokens by descending frequency and return the top 5
        return termFreq.entrySet()
                .stream()
                .sorted((e1, e2) -> e2.getValue().compareTo(e1.getValue()))
                .limit(config.getInt("numOfDocsToRetrieveForPrf"))
                .map(Map.Entry::getKey)
                .toArray(String[]::new);
    }

    public static Map<String, List<String>> retrieveDocuments(ScoreDoc[] scoreDocs,
                                                              IndexReader reader,
                                                              String queryTitle) throws IOException {

        int numDocToRerank = config.getInt("numOfDocsToRerank");
        Map<String, List<String>> documentMap = new HashMap<>();
        if (scoreDocs.length == 0)
            return new HashMap<>();
        if (scoreDocs.length < numDocToRerank)
            numDocToRerank = scoreDocs.length;

        List<String> documents = new ArrayList<>();
        for (int i = 0; i < numDocToRerank; i++) {
            Document doc = reader.storedFields().document(scoreDocs[i].doc);
            String docBody = doc.get(ParsedDocument.FIELDS.BODY);
            documents.add(docBody);
        }
        documentMap.put(queryTitle, documents);

        return documentMap;
    }

    public static String reRank(String query, List<String> documents, int numDocToRerank, String key) {

        switch (config.getString("reRankEndPoint")) {
            case "Cohere":
                Cohere cohere = Cohere.builder().token(key).clientName("snippet").build();
                List<RerankRequestDocumentsItem> rerankDocuments = new ArrayList<>();
                documents.forEach(item -> rerankDocuments.add(RerankRequestDocumentsItem.of(item)));
                RerankResponse responseCo = cohere.rerank(RerankRequest.builder().query(query).documents(rerankDocuments).model("rerank-multilingual-v3.0").topN(numDocToRerank).build());
                return responseCo.toString();
            case "Local":
                try {
                    JSONObject requestBody = new JSONObject();
                    requestBody.put("query", query);
                    requestBody.put("documents", documents);
                    requestBody.put("top_n", numDocToRerank);

                    URL url = URI.create("http://localhost:8000/rerank").toURL();
                    HttpURLConnection con = (HttpURLConnection) url.openConnection();
                    con.setRequestMethod("POST");
                    con.setRequestProperty("Content-Type", "application/json");
                    con.setConnectTimeout(100000);
                    con.setReadTimeout(100000);
                    con.setDoOutput(true);

                    try (OutputStream os = con.getOutputStream()) {
                        byte[] input = requestBody.toString().getBytes(StandardCharsets.UTF_8);
                        os.write(input, 0, input.length);
                    }

                    int status = con.getResponseCode();
                    InputStream is = (status < 400) ? con.getInputStream() : con.getErrorStream();
                    StringBuilder response = new StringBuilder();
                    try (BufferedReader br = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))) {
                        String line;
                        while ((line = br.readLine()) != null) {
                            response.append(line.trim());
                        }
                    }
                    return response.toString();
                } catch (IOException e) {
                    throw new RuntimeException("Reranking Error", e);
                }
            default:
                throw new IllegalArgumentException("Reranking endpoint not configured: " + config.getString("reRankService"));
        }
    }

    public static SortedMap<Integer, Float> jsonHandler(String response) {
        JSONObject json = new JSONObject(response);
        JSONArray resultsArray = json.getJSONArray("results");
        SortedMap<Integer, Float> idScoreMap = new TreeMap<>(Comparator.reverseOrder());

        for (int i = 0; i < resultsArray.length(); i++) {
            JSONObject resultObj = resultsArray.getJSONObject(i);
            int index = resultObj.getInt("index");
            float relevanceScore = (float) resultObj.getDouble("relevance_score");
            idScoreMap.put(index, relevanceScore);
        }
        return idScoreMap;
    }

    public static void fixScores(Map<Integer, Float> newScores, ScoreDoc[] sd, int numDocToRerank, float alpha) {
        if (sd.length < numDocToRerank)
            numDocToRerank = sd.length;

        // Normalize scores and combine with reranker scores
        for (int i = 0; i < numDocToRerank; i++) {
            float rerankerScore = newScores.getOrDefault(i, 0.0f);
            sd[i].score = (1 - alpha) * sd[i].score + alpha * rerankerScore;
        }

        // method to sort the array sd
        Arrays.sort(sd, (sd1, sd2) -> Float.compare(sd2.score, sd1.score));

    }

    /**
     * Detects the language of the given text using OpenNLP's LanguageDetector.
     *
     * @param text The text for which to detect the language.
     * @return The detected language code (e.g., "fr" for French, "en" for English).
     * @throws Exception If an error occurs during language detection.
     */
    public static String detectLanguage(String text) throws Exception {
        LanguageDetectorModel model;
        
        String modelFile = config.getString("languageDetectorModel");
        if (modelFile == null)
            throw new NullPointerException("Language detector model file name cannot be null.");
        if (modelFile.isEmpty())
            throw new IllegalArgumentException("Language detector model file name cannot be empty.");
        try {
            InputStream in = Files.newInputStream(Paths.get(modelFile));
            model = new LanguageDetectorModel(in);
            in.close();

            LanguageDetectorME detector = new LanguageDetectorME(model);
            double maxProb = -1.0;
            String bestLang = "fr";

            Language[] languages = detector.predictLanguages(text);
            for (Language lang : languages) {
                if (lang.getLang().equals("en") || lang.getLang().equals("fr")) {
                    if (lang.getConfidence() > maxProb) {
                        maxProb = lang.getConfidence();
                        bestLang = lang.getLang();
                    }
                }
            }
            return bestLang;
        } catch (IOException e) {
            throw new IllegalStateException(String.format("Unable to load the model %s: %s", modelFile, e.getMessage()), e);
        }
    }

    /**
     * Corrects the input text using language detection and grammar checking.
     *
     * @param input The input text to be corrected.
     * @return The corrected text.
     * @throws IOException If an I/O error occurs during language detection or grammar checking.
     */
    public static String correctText(String input, String language) throws IOException {
        //String apiUrl = "https://api.languagetool.org/v2/check";
        String apiUrl = "http://localhost:8081/v2/check";
        String params = "text=" + URLEncoder.encode(input, StandardCharsets.UTF_8)
                + "&language=" + URLEncoder.encode(language, StandardCharsets.UTF_8)
                + "&enabledOnly=false"
                + "&disabledRules=UPPERCASE_SENTENCE_START";

        URL url = URI.create(apiUrl).toURL();
        HttpURLConnection conn = (HttpURLConnection) url.openConnection();
        conn.setRequestMethod("POST");
        conn.setDoOutput(true);
        conn.setRequestProperty("Content-Type", "application/x-www-form-urlencoded; charset=UTF-8");
        conn.setRequestProperty("Accept", "application/json");

        try (OutputStream os = conn.getOutputStream()) {
            os.write(params.getBytes(StandardCharsets.UTF_8));
        }

        StringBuilder response = new StringBuilder();
        try (BufferedReader br = new BufferedReader(new InputStreamReader(conn.getInputStream(), StandardCharsets.UTF_8))) {
            String line;
            while ((line = br.readLine()) != null) {
                response.append(line);
            }
        }

        JSONObject json = new JSONObject(response.toString());
        JSONArray matches = json.getJSONArray("matches");
        StringBuilder corrected = new StringBuilder(input);

        for (int i = matches.length() - 1; i >= 0; i--) {
            JSONObject match = matches.getJSONObject(i);
            JSONArray replacements = match.getJSONArray("replacements");
            if (replacements.length() > 0) {
                String replacement = replacements.getJSONObject(0).getString("value");
                int offset = match.getInt("offset");
                int length = match.getInt("length");
                corrected.replace(offset, offset + length, replacement);
            }
        }
        String ret = String.join(" ", queryAnalyzer(new FrenchAnalyzer(), corrected.toString()));
        System.out.println(ret);
        return ret;
    }

    public static void main(String[] args) {
        try {
            String query = "acheter carte cadeau";
            String[] relatedTerms = getRelatedTermsFromLLM(query, config.getOpenApiKey());
            System.out.println("Parole chiave correlate:");
            Arrays.stream(relatedTerms).forEach(System.out::println);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
